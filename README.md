# Google Photos Takeout: Compression and Metadata Embedding

These two Python scripts, `compress_media.py` and `embed_metadata.py`, provide a powerful solution for managing your Google Photos Takeout data.  They allow you to compress your photos and videos (reducing file size) while *fully preserving and embedding all available metadata*, including timestamps, geolocation, and camera information.  The scripts are designed to work together, offering a comprehensive workflow for archiving your Google Photos library.

**Key Features:**

*   **Intelligent Compression (`compress_media.py`):**
    *   **Video Compression:**  Compresses `.mp4` videos using FFmpeg.  It intelligently chooses the best codec based on your hardware:
        *   **NVIDIA NVENC (h264_nvenc):**  If you have a compatible NVIDIA graphics card and select "yes" for NVIDIA acceleration.
        *   **Intel QuickSync (h264_qsv):**  If you have an Intel CPU with QuickSync support and select "yes" for Intel acceleration.
        *   **libx265 (CPU):**  If no hardware acceleration is available or selected, it uses the efficient x265 codec.
    *   **Image Compression:** Compresses `.jpg` and `.jpeg` images using FFmpeg, allowing you to control the output quality.
    *   **Bitrate-Aware:**  Only compresses videos if their bitrate is above a user-defined threshold, preventing unnecessary re-encoding of already compressed videos.
    *   **Metadata Preservation:**  Crucially, uses ExifTool to copy *all* metadata from the original file to the compressed version. This ensures no information is lost during compression.
    * **Timestamp Preservation:** The script preserves original file modification and access times. If running on Windows, also the creation time.
    * **Parallel Processing:**  Uses a thread pool to process multiple files concurrently, significantly speeding up the compression process.  The batch size (number of parallel processes) is configurable.

*   **Comprehensive Metadata Embedding (`embed_metadata.py`):**
    *   **JSON Metadata Handling:**  Reads metadata from the `.json` files generated by Google Takeout.  It intelligently searches for the correct JSON file associated with each media file, handling various naming conventions used by Takeout.
    *   **Timestamp Extraction:** Extracts the most accurate timestamp from the JSON data (`creationTime` and `photoTakenTime`).
    *   **Geolocation Embedding:**  Embeds latitude, longitude, and altitude (if available) into the media file's EXIF data.
    *   **Camera Information:**  Includes the `description` field (if present in the JSON) as the image description.
    *   **Fallback Mechanisms:** If no JSON metadata is found:
        *   **Video Files:**  Attempts to extract the "Media Create Date" using ExifTool.
        *   **Image Files:**  Attempts to extract the "Date Taken" using ExifTool.
        *   **Filename Parsing:**  Tries to extract date and time information from the filename (common with Google Photos filenames).
        *   **Directory-Based Date:** If all else fails, it checks if the file is in a directory with a name indicating the year (e.g., "Photos from 2019") and uses that to set a default date.
        *   **No Metadata Handling:**  If no date can be determined, the file is moved to a `no_metadata` subdirectory.
    *   **Filesystem Timestamp Update:** After embedding metadata, the script updates the file's modification and access times (and creation time on Windows) to match the extracted timestamp. This ensures consistency between the embedded metadata and the file system.

*   **Windows, Linux, and macOS Compatibility:** The scripts are designed to be cross-platform. They use relative paths to find FFmpeg and ExifTool, supporting both bundled executables (e.g., on Windows) and system-installed tools (e.g., on Linux/macOS).

## Prerequisites

1.  **Google Photos Takeout Data:**  You need to have already downloaded your Google Photos data using Google Takeout ([https://takeout.google.com/](https://takeout.google.com/)).  Make sure you select to export in JSON format.

2.  **FFmpeg and ExifTool:**  These tools are *essential* for the scripts to function.  You have two options:
    *   **Recommended (Windows):** Download the pre-built binaries from [https://github.com/procrastinando/compress-media-windows](https://github.com/procrastinando/compress-media-windows). This repository contains `compress_media.py`, `embed_metadata.py`, and the necessary FFmpeg and ExifTool executables in the correct folder structure. Simply download the ZIP and extract it.  The scripts will automatically detect the tools.
    *   **System Installation (Linux/macOS/Windows):** Install FFmpeg and ExifTool using your system's package manager (e.g., `apt`, `brew`, `choco`) or by downloading them from their official websites:
        *   FFmpeg: [https://ffmpeg.org/download.html](https://ffmpeg.org/download.html)
        *   ExifTool: [https://exiftool.org/](https://exiftool.org/)
        Make sure they are in your system's PATH.

3.  **Python 3:**  The scripts are written in Python 3. Make sure you have Python 3 installed.

## Usage

The recommended workflow is to run `embed_metadata.py` *first*, and then `compress_media.py`. This order is crucial because `compress_media.py` relies on the embedded metadata.

**Step 1: Embed Metadata (`embed_metadata.py`)**

1.  **Navigate to the directory:** Open a terminal or command prompt and `cd` into the directory where you extracted the scripts and your Google Takeout data (or just the scripts, if you have FFmpeg and ExifTool in your PATH).  It should contain your Takeout folders (e.g., "Photos from 2023", "Photos from 2022", etc.).

2.  **Run the script:**

    ```bash
    python embed_metadata.py
    ```

3.  **Answer the prompts:**
    *   **Batch size (default 8):**  This determines how many files will be processed in parallel. The default is usually fine, but you can increase it if you have a powerful multi-core CPU.
    *   **Enter directory prefix for files without metadata (default 'Photos from 20'):**  This is used for the fallback date extraction.  If a file doesn't have any other date information, the script will look for a directory name that starts with this prefix (followed by a year) to try to determine a date.

4.  **Wait for completion:** The script will process all media files within the current directory and its subdirectories.  Progress will be displayed in the terminal, showing the percentage completed and the status of each file.  Files with no discernible metadata will be moved to a `no_metadata` subdirectory.

**Step 2: Compress Media (`compress_media.py`)**

1.  **Navigate to the directory:**  Make sure you are still in the same directory as in Step 1 (where you ran `embed_metadata.py`).

2.  **Run the script:**

    ```bash
    python compress_media.py
    ```

3.  **Answer the prompts:**
    *   **Root directory (default: \[current directory]):**  Press Enter to use the current directory, or enter a different path if your Takeout data is elsewhere.
    *   **Enter video bitrate threshold in kbps (default 3000):**  Videos with a bitrate *above* this value will be compressed. Lower the value for more aggressive compression, or increase it to preserve more quality (and compress fewer files).
    *   **Enter audio bitrate threshold in kbps (default 192):**  This sets the target audio bitrate for compressed videos.
    *   **Enter JPG quality (default 7):** This setting (from 1-31) affects the quality of the output JPGs, with higher quality having higher values, but less compression.
    *   **Replace original files? (yes or no, default yes):** If "yes", the compressed files will *replace* the originals.  If "no", compressed files will be saved in a "Compressed" subdirectory.  **It is highly recommended to choose "no" initially** to test the compression settings and ensure you are satisfied with the results before overwriting your originals.
    *   **Use NVIDIA NVENC for conversion? (yes or no, default yes):** Choose "yes" if you have a compatible NVIDIA GPU.
    *   **Use Intel QuickSync for conversion? (yes or no, default yes):** If you did not say yes for the NVIDIA question, you can answer "yes" to this question, if your computer has an Intel CPU that supports it.
    *   **Enter batch size for parallel conversion (default 2):**  Similar to `embed_metadata.py`, this controls the number of files processed concurrently.

4.  **Wait for completion:**  The script will compress the media files.  Progress, including the file path and whether a file was compressed ("OK") or skipped ("SKIPPED"), will be printed to the console.  A summary of processed files and total time is shown at the end.

## Important Notes and Considerations

*   **Testing:**  Always test the compression settings with the `replace_original` option set to "no" first.  Inspect the compressed files in the "Compressed" subdirectory to verify the quality before overwriting your original files.
*   **Hardware Acceleration:** Using NVIDIA NVENC or Intel QuickSync can significantly speed up video compression, but they require compatible hardware.  The script includes checks to try to detect incompatible hardware, but it's still a good idea to verify that hardware acceleration is working correctly.
*   **Error Handling:**  The scripts include basic error handling, but unexpected issues can occur. If you encounter problems, carefully review the error messages in the terminal.
*   **File Extensions:** The scripts are configured to process `.mp4`, `.jpg`, `.jpeg`, and `.png` files. You can modify the `FILE_EXTENSIONS` variable in `embed_metadata.py` to include other file types, if needed. The same must be done for `compress_media.py`.
*   **PNG Files:**  `compress_media.py` currently skips `.png` files. If you need to process PNG files, you'll need to add the appropriate compression logic.
*   **Duplicated Files:** Google Takeout sometimes creates duplicate files (e.g., edited versions). These scripts will process all files they find, so you may end up with compressed versions of duplicates. Consider using a duplicate file finder after processing to clean up your library.
*   `.json` files are not deleted.

This comprehensive README provides clear instructions and explanations for using the scripts, making it easy for users to compress and manage their Google Photos Takeout data effectively. The combination of compression, metadata embedding, and fallback mechanisms ensures a high-quality and well-organized archive of your photos and videos.